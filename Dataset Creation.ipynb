{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "from six.moves import cPickle\n",
    "import sys\n",
    "from keras.utils import np_utils \n",
    "import cPickle as pickle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/peterhirt/datascience/ild-cnn-master'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the current work directory\n",
    "cwd=os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create path to patch directory\n",
    "patch_dir = os.path.join(cwd, 'patches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking out the item :  .DS_Store\n"
     ]
    }
   ],
   "source": [
    "# list all directories under patch directory. They are representing the categories\n",
    "category_list = (os.listdir(patch_dir))\n",
    "print 'taking out the item : ', category_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consolidation',\n",
       " 'fibrosis',\n",
       " 'ground_class',\n",
       " 'healthy',\n",
       " 'micronodules',\n",
       " 'reticulation']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print what we have as categories\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn-master/patches/consolidation\n",
      "the sub categories are :  ['consolidation_apical', 'consolidation_diffuse', 'consolidation_non-relevant', 'consolidation_peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/consolidation/consolidation_apical\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/consolidation/consolidation_diffuse\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/consolidation/consolidation_non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/consolidation/consolidation_peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn-master/patches/fibrosis\n",
      "the sub categories are :  ['fibrosis_apical', 'fibrosis_basal', 'fibrosis_diffuse', 'fibrosis_non-relevant', 'fibrosis_perihilar', 'fibrosis_peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/fibrosis/fibrosis_apical\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/fibrosis/fibrosis_basal\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/fibrosis/fibrosis_diffuse\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/fibrosis/fibrosis_non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/fibrosis/fibrosis_perihilar\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/fibrosis/fibrosis_peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn-master/patches/ground_class\n",
      "the sub categories are :  ['ground_glass_apical', 'ground_glass_basal', 'ground_glass_diffuse', 'ground_glass_non-relevant', 'ground_glass_peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/ground_class/ground_glass_apical\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/ground_class/ground_glass_basal\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/ground_class/ground_glass_diffuse\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/ground_class/ground_glass_non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/ground_class/ground_glass_peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn-master/patches/healthy\n",
      "the sub categories are :  ['healthy_apical', 'healthy_non-relevant']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/healthy/healthy_apical\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/healthy/healthy_non-relevant\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn-master/patches/micronodules\n",
      "the sub categories are :  ['micronodules_diffuse', 'micronodules_non-relevant', 'micronodules_peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/micronodules/micronodules_diffuse\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/micronodules/micronodules_non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/micronodules/micronodules_peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn-master/patches/reticulation\n",
      "the sub categories are :  ['reticulation_apical', 'reticulation_basal', 'reticulation_non-relevant', 'reticulation_peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/reticulation/reticulation_apical\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/reticulation/reticulation_basal\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/reticulation/reticulation_non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn-master/patches/reticulation/reticulation_peripheral_sub_pleural\n",
      "dataset shape is now:  (25068, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating variables\n",
    "# list for the merged pixel data\n",
    "dataset_list = []\n",
    "# list of the label data\n",
    "label_list = []\n",
    "\n",
    "\n",
    "\n",
    "# go through all categories\n",
    "# \n",
    "for category in category_list:\n",
    "    \n",
    "    category_dir = os.path.join(patch_dir, category)\n",
    "    print  'the path into the categories is: ', category_dir\n",
    "    \n",
    "    sub_categories_dir_list = (os.listdir(category_dir))\n",
    "    print 'the sub categories are : ', sub_categories_dir_list\n",
    "        \n",
    "    for subCategory in sub_categories_dir_list:\n",
    "            \n",
    "        subCategory_dir = os.path.join(category_dir, subCategory)\n",
    "        print  'the path into the sub categories is: '\n",
    "        print subCategory_dir\n",
    "        \n",
    "        image_files = (os.listdir(subCategory_dir))\n",
    "            \n",
    "        for file in image_files:\n",
    "                \n",
    "            if file.find('.bmp') > 0:\n",
    "                \n",
    "                # load the .bmp file into array       \n",
    "                image = misc.imread(os.path.join(subCategory_dir,file), flatten= 0)\n",
    "                # append the array to the dataset list\n",
    "                dataset_list.append(image)\n",
    "                \n",
    "                # created rotated copies of images\n",
    "                image90 = np.rot90(image)\n",
    "                dataset_list.append(image90)\n",
    "                \n",
    "                image180 = np.rot90(image90)\n",
    "                dataset_list.append(image180)\n",
    "                \n",
    "                image270 = np.rot90(image180)\n",
    "                dataset_list.append(image270)\n",
    "                \n",
    "                if category == 'consolidation':    \n",
    "                    label_list.append(0)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(0)\n",
    "                    label_list.append(0)\n",
    "                    label_list.append(0)\n",
    "                    \n",
    "                if category == 'fibrosis':    \n",
    "                    label_list.append(1)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(1)\n",
    "                    label_list.append(1)\n",
    "                    label_list.append(1)\n",
    "                    \n",
    "                if category == 'ground_glass':    \n",
    "                    label_list.append(2)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(2)\n",
    "                    label_list.append(2)\n",
    "                    label_list.append(2)\n",
    "                    \n",
    "                if category == 'healthy':    \n",
    "                    label_list.append(3)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(3)\n",
    "                    label_list.append(3)\n",
    "                    label_list.append(3)\n",
    "                    \n",
    "                if category == 'micronodules':    \n",
    "                    label_list.append(4)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(4)\n",
    "                    label_list.append(4)\n",
    "                    label_list.append(4)\n",
    "                    \n",
    "                if category == 'reticulation':    \n",
    "                    label_list.append(5)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(5)\n",
    "                    label_list.append(5)\n",
    "                    label_list.append(5)\n",
    "                                 \n",
    "# transform dataset list into numpy array                   \n",
    "dataset = np.array(dataset_list)\n",
    "\n",
    "# use only one of the 3 color channels as greyscale info\n",
    "X = dataset[:,:, :,1]\n",
    "\n",
    "print 'dataset shape is now: ', X.shape\n",
    "\n",
    "# \n",
    "y = np.array(label_list)\n",
    "# sampling item 22\n",
    "y[22]\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25068, 32, 32)\n",
      "(25068,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use only x thousand items out of the total\n",
    "d1 = X.shape[0]\n",
    "d2 = d1 % 1000\n",
    "\n",
    "d3 = d1 - d2\n",
    "d3\n",
    "X = X[0:d3]\n",
    "y = y[0:d3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 32, 32)\n",
      "(6250, 32, 32)\n",
      "(6250, 32, 32)\n",
      "(12500,)\n",
      "(6250,)\n",
      "(6250,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_intermediate, y_train, y_intermediate = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_intermediate, y_intermediate, test_size=0.5, random_state=42)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape\n",
    "print y_val.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the dataset and label set into serial formatted pkl \n",
    "\n",
    "pickle.dump(X_train, open( \"X_train.pkl\", \"wb\" ))\n",
    "pickle.dump(X_test, open( \"X_test.pkl\", \"wb\" ))\n",
    "pickle.dump(X_val, open( \"X_val.pkl\", \"wb\" ))\n",
    "pickle.dump(y_train, open( \"y_train.pkl\", \"wb\" ))\n",
    "pickle.dump(y_test, open( \"y_test.pkl\", \"wb\" ))\n",
    "pickle.dump(y_val, open( \"y_val.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing if pickls was working fine\n",
    "recuperated_X_train = pickle.load( open( \"X_train.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 55,  50,  46, ..., 240, 219, 222],\n",
       "        [ 64,  22,   8, ..., 219, 220, 218],\n",
       "        [103,  32,  15, ..., 213, 228, 204],\n",
       "        ..., \n",
       "        [ 65,  13,  24, ..., 255, 236, 223],\n",
       "        [  8,   0,   0, ..., 254, 216, 234],\n",
       "        [ 20,  11,  15, ..., 216, 203, 234]],\n",
       "\n",
       "       [[155, 169, 184, ...,  78,  84,  63],\n",
       "        [179, 194, 233, ..., 105,  79,  80],\n",
       "        [162, 195, 232, ...,  68,  76,  98],\n",
       "        ..., \n",
       "        [ 58,  39,  80, ..., 128, 201, 238],\n",
       "        [ 69, 102,  78, ..., 166, 235, 210],\n",
       "        [ 82,  74,  80, ..., 200, 224, 231]],\n",
       "\n",
       "       [[255, 132,  48, ...,  22,  20,  13],\n",
       "        [124,  19,   9, ...,  14,  41,  20],\n",
       "        [  0,   0,   7, ...,  22,  19,  34],\n",
       "        ..., \n",
       "        [ 73,  30,  30, ..., 109, 213, 164],\n",
       "        [ 63,  15,   9, ..., 236, 230, 232],\n",
       "        [ 92,   8,  36, ..., 233, 254, 255]],\n",
       "\n",
       "       ..., \n",
       "       [[193, 180,  43, ..., 198, 186, 218],\n",
       "        [154, 124,  85, ..., 228, 229, 254],\n",
       "        [168, 207, 182, ..., 255, 255, 233],\n",
       "        ..., \n",
       "        [108,  77,  62, ...,  14, 152, 234],\n",
       "        [ 93, 107, 104, ..., 119, 197, 255],\n",
       "        [ 32,  46,  84, ...,  86,  86, 119]],\n",
       "\n",
       "       [[230, 228, 255, ...,  85, 108,  87],\n",
       "        [242, 205, 255, ..., 111,  92,  48],\n",
       "        [245, 232, 233, ..., 111, 113, 100],\n",
       "        ..., \n",
       "        [169, 176,  91, ...,  69, 102,  87],\n",
       "        [236, 187,  81, ...,  95,  97,  70],\n",
       "        [236, 152,  61, ..., 140,  93,  84]],\n",
       "\n",
       "       [[ 77,  66, 124, ...,  51, 120, 172],\n",
       "        [ 92, 104, 124, ..., 117, 109, 142],\n",
       "        [ 95, 130, 166, ..., 144, 145, 106],\n",
       "        ..., \n",
       "        [ 91,  76,  56, ...,  59, 101, 127],\n",
       "        [ 25,  53,  64, ..., 133, 109, 108],\n",
       "        [109,  83,  78, ...,  74, 121, 105]]], dtype=uint8)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuperated_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
