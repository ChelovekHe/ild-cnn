{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "from six.moves import cPickle\n",
    "import sys\n",
    "from keras.utils import np_utils \n",
    "import cPickle as pickle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define the working directory\n",
    "cwd=os.getcwd()\n",
    "(cwdtop,tail)=os.path.split(cwd)\n",
    "patch_dir=os.path.join(cwdtop,'patches')\n",
    "pickle_dir=os.path.join(cwdtop,'pickle')\n",
    "if not os.path.exists(pickle_dir):\n",
    " os.mkdir(pickle_dir)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['consolidation', 'fibrosis', 'ground_glass', 'healthy', 'micronodules', 'reticulation']\n"
     ]
    }
   ],
   "source": [
    "#define a list of used labels\n",
    "usedclassif = ['consolidation',\n",
    " 'fibrosis',\n",
    " 'ground_glass',\n",
    " 'healthy',\n",
    " 'micronodules',\n",
    " 'reticulation']\n",
    "print (usedclassif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define a dictionary with labels\n",
    "classif={}\n",
    "i=0\n",
    "for f in usedclassif:\n",
    "    classif[f]=i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'micronodules': 4, 'healthy': 3, 'ground_glass': 2, 'consolidation': 0, 'reticulation': 5, 'fibrosis': 1}\n"
     ]
    }
   ],
   "source": [
    "print classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all directories under patch directory. They are representing the categories\n",
    "category_list = (os.listdir(patch_dir))\n",
    "##print 'taking out the item : ', category_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bronchial_wall_thickening',\n",
       " 'bronchiectasis',\n",
       " 'consolidation',\n",
       " 'cysts',\n",
       " 'fibrosis',\n",
       " 'ground_glass',\n",
       " 'macronodules',\n",
       " 'Nouveau document texte.txt',\n",
       " 'peripheral_micronodules',\n",
       " 'reticulation']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print what we have as categories\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the path into the categories is:  C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\consolidation\n",
      "the sub categories are :  ['diffuse', 'non-relevant', 'peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\consolidation\\diffuse\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\consolidation\\non-relevant\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\consolidation\\peripheral_sub_pleural\n",
      "the path into the categories is:  C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\fibrosis\n",
      "the sub categories are :  ['basal', 'non-relevant']\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\fibrosis\\basal\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\fibrosis\\non-relevant\n",
      "the path into the categories is:  C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\ground_glass\n",
      "the sub categories are :  ['basal', 'diffuse', 'non-relevant', 'peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\ground_glass\\basal\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\ground_glass\\diffuse\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\ground_glass\\non-relevant\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\ground_glass\\peripheral_sub_pleural\n",
      "the path into the categories is:  C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\reticulation\n",
      "the sub categories are :  ['basal']\n",
      "the path into the sub categories is: \n",
      "C:\\Users\\sylvain\\Documents\\boulot\\startup\\radiology\\ILDtempo\\ild-cnn\\patches\\reticulation\\basal\n"
     ]
    }
   ],
   "source": [
    "# creating variables\n",
    "# list for the merged pixel data\n",
    "dataset_list = []\n",
    "# list of the label data\n",
    "label_list = []\n",
    "\n",
    "\n",
    "\n",
    "# go through all categories\n",
    "# \n",
    "for category in category_list:\n",
    "    if category in usedclassif:\n",
    "        category_dir = os.path.join(patch_dir, category)\n",
    "        print  'the path into the categories is: ', category_dir\n",
    "\n",
    "        sub_categories_dir_list = (os.listdir(category_dir))\n",
    "        print 'the sub categories are : ', sub_categories_dir_list\n",
    "\n",
    "        for subCategory in sub_categories_dir_list:\n",
    "\n",
    "            subCategory_dir = os.path.join(category_dir, subCategory)\n",
    "            print  'the path into the sub categories is: '\n",
    "            print subCategory_dir\n",
    "\n",
    "            image_files = (os.listdir(subCategory_dir))\n",
    "\n",
    "            for file in image_files:\n",
    "\n",
    "                if file.find('.bmp') > 0:\n",
    "\n",
    "                    # load the .bmp file into array       \n",
    "                    image = misc.imread(os.path.join(subCategory_dir,file), flatten= 0)\n",
    "                    # append the array to the dataset list\n",
    "                    dataset_list.append(image)\n",
    "\n",
    "                    # created rotated copies of images\n",
    "                    image90 = np.rot90(image)\n",
    "                    dataset_list.append(image90)\n",
    "\n",
    "                    image180 = np.rot90(image90)\n",
    "                    dataset_list.append(image180)\n",
    "\n",
    "                    image270 = np.rot90(image180)\n",
    "                    dataset_list.append(image270)\n",
    "\n",
    "                    # append  lables \n",
    "                    label_list.append(classif[category])\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(classif[category])\n",
    "                    label_list.append(classif[category])\n",
    "                    label_list.append(classif[category])\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 1016)\n"
     ]
    }
   ],
   "source": [
    "print (len(dataset_list),len(label_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset shape is now:  (1000L, 32L, 32L)\n"
     ]
    }
   ],
   "source": [
    "nb_elem = 25000 \n",
    "indices = []  \n",
    "resultatx=[]\n",
    "resultaty= [] \n",
    "while nb_elem > 0:  \n",
    "    i = random.randint(0, len(dataset_list) -1)  \n",
    "    while i in indices: # tant que le tirage redonne un nombre déjà choisi  \n",
    "        i = random.randint(0, len(dataset_list) -1)  \n",
    "    indices.append(i)  \n",
    "    nb_elem = nb_elem - 1  \n",
    "\n",
    "for index in indices:  \n",
    "    resultatx.append(dataset_list[index])  \n",
    "    resultaty.append(label_list[index]) \n",
    "\n",
    "# transform dataset list into numpy array                   \n",
    "X = np.array(resultatx)\n",
    "#this is already in greyscale\n",
    "# use only one of the 3 color channels as greyscale info\n",
    "#X = dataset[:,:, :,1]\n",
    "\n",
    "print 'dataset shape is now: ', X.shape\n",
    "\n",
    "# \n",
    "y = np.array(resultaty)\n",
    "# sampling item 22\n",
    "#y[22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 1016)\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print (len(dataset_list),len(label_list))\n",
    "print (len(resultatx),len(resultaty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000L, 32L, 32L)\n",
      "(1000L,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500L, 32L, 32L)\n",
      "(250L, 32L, 32L)\n",
      "(250L, 32L, 32L)\n",
      "(500L,)\n",
      "(250L,)\n",
      "(250L,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_intermediate, y_train, y_intermediate = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_intermediate, y_intermediate, test_size=0.5, random_state=42)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape\n",
    "print y_val.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the dataset and label set into serial formatted pkl \n",
    "\n",
    "pickle.dump(X_train, open( os.path.join(pickle_dir,\"X_train.pkl\"), \"wb\" ))\n",
    "pickle.dump(X_test, open( os.path.join(pickle_dir,\"X_test.pkl\"), \"wb\" ))\n",
    "pickle.dump(X_val, open(os.path.join(pickle_dir,\"X_val.pkl\"), \"wb\" ))\n",
    "pickle.dump(y_train, open( os.path.join(pickle_dir,\"y_train.pkl\"), \"wb\" ))\n",
    "pickle.dump(y_test, open( os.path.join(pickle_dir,\"y_test.pkl\"), \"wb\" ))\n",
    "pickle.dump(y_val, open( os.path.join(pickle_dir,\"y_val.pkl\"), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing if pickls was working fine\n",
    "recuperated_X_train = pickle.load( open( os.path.join(pickle_dir,\"X_train.pkl\"), \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[154, 155, 154, ..., 116, 115, 108],\n",
       "        [153, 156, 153, ..., 125, 119, 110],\n",
       "        [153, 153, 152, ..., 123, 117, 111],\n",
       "        ..., \n",
       "        [156, 156, 162, ..., 155, 153, 151],\n",
       "        [155, 159, 164, ..., 164, 162, 153],\n",
       "        [153, 160, 161, ..., 156, 163, 161]],\n",
       "\n",
       "       [[ 22,  22,  23, ...,  11,   9,  22],\n",
       "        [ 18,  23,  23, ...,  18,  17,  17],\n",
       "        [ 21,  16,  26, ...,  17,  18,  17],\n",
       "        ..., \n",
       "        [ 12,  14,  30, ...,  93,  89,  79],\n",
       "        [ 11,  12,  32, ...,  90,  89,  96],\n",
       "        [  8,  13,  26, ...,  91, 101,  86]],\n",
       "\n",
       "       [[ 24,  45,  56, ...,   0,   0,   1],\n",
       "        [ 32,  41,  50, ...,   0,   0,   0],\n",
       "        [ 27,  43,  46, ...,  17,  10,   3],\n",
       "        ..., \n",
       "        [ 61,  50,  57, ...,  58,  49,  52],\n",
       "        [ 48,  56,  42, ...,  53,  61,  48],\n",
       "        [ 46,  48,  43, ...,  53,  58,  47]],\n",
       "\n",
       "       ..., \n",
       "       [[154, 161, 162, ..., 137, 125, 117],\n",
       "        [152, 156, 161, ..., 135, 134, 128],\n",
       "        [148, 155, 158, ..., 119, 138, 145],\n",
       "        ..., \n",
       "        [106, 110, 119, ..., 109, 113, 114],\n",
       "        [113, 112, 115, ..., 113, 111, 112],\n",
       "        [121, 113, 121, ..., 114, 110, 111]],\n",
       "\n",
       "       [[ 20,  13,  18, ...,  21,  17,  22],\n",
       "        [ 18,  15,  32, ...,  19,  17,  17],\n",
       "        [ 15,  33,  45, ...,  18,  11,  14],\n",
       "        ..., \n",
       "        [ 18,  18,  19, ...,  24,  28,  20],\n",
       "        [ 10,  10,  10, ...,  33,  32,  30],\n",
       "        [ 15,  13,  14, ...,  39,  32,  33]],\n",
       "\n",
       "       [[  5,   0,  11, ...,  41,  38,  19],\n",
       "        [ 56,  37,  44, ...,  26,  43,  45],\n",
       "        [102,  94,  96, ...,  21,  16,  18],\n",
       "        ..., \n",
       "        [ 25,  20,  13, ...,  34,  36,  26],\n",
       "        [ 44,  12,  15, ...,  26,  28,  25],\n",
       "        [ 26,  18,  12, ...,  23,  18,  23]]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuperated_X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
