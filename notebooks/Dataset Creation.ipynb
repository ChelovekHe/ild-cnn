{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterhirt/anaconda/envs/theano/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.data_utils import get_file\n",
    "from six.moves import cPickle\n",
    "import sys\n",
    "from keras.utils import np_utils \n",
    "import cPickle as pickle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/peterhirt/datascience/ild-cnn/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the current work directory\n",
    "cwd=os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/peterhirt/datascience/ild-cnn\n"
     ]
    }
   ],
   "source": [
    "one_folder_up = os.path.dirname(os.getcwd())\n",
    "print one_folder_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/peterhirt/datascience/ild-cnn/patches\n"
     ]
    }
   ],
   "source": [
    "# create path to patch directory\n",
    "patch_dir = os.path.join(one_folder_up, 'patches')\n",
    "print patch_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking out the item :  .DS_Store\n"
     ]
    }
   ],
   "source": [
    "# list all directories under patch directory. They are representing the categories\n",
    "category_list = (os.listdir(patch_dir))\n",
    "print 'taking out the item : ', category_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consolidation',\n",
       " 'fibrosis',\n",
       " 'ground_glass',\n",
       " 'healthy',\n",
       " 'micronodules',\n",
       " 'reticulation']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print what we have as categories\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn/patches/consolidation\n",
      "the sub categories are :  ['apical', 'diffuse', 'non-relevant', 'peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/consolidation/diffuse\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/consolidation/non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/consolidation/peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn/patches/fibrosis\n",
      "the sub categories are :  ['apical', 'basal', 'diffuse', 'non-relevant', 'perihilar', 'peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/fibrosis/basal\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/fibrosis/diffuse\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/fibrosis/non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/fibrosis/perihilar\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/fibrosis/peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn/patches/ground_glass\n",
      "the sub categories are :  ['apical', 'basal', 'diffuse', 'non-relevant', 'peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/ground_glass/basal\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/ground_glass/diffuse\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/ground_glass/non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/ground_glass/peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn/patches/healthy\n",
      "the sub categories are :  ['apical', 'non-relevant']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/healthy/non-relevant\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn/patches/micronodules\n",
      "the sub categories are :  ['diffuse', 'non-relevant', 'peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/micronodules/non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/micronodules/peripheral_sub_pleural\n",
      "the path into the categories is:  /Users/peterhirt/datascience/ild-cnn/patches/reticulation\n",
      "the sub categories are :  ['apical', 'basal', 'non-relevant', 'peripheral_sub_pleural']\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/reticulation/basal\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/reticulation/non-relevant\n",
      "the path into the sub categories is: \n",
      "/Users/peterhirt/datascience/ild-cnn/patches/reticulation/peripheral_sub_pleural\n",
      "dataset shape is now:  (20948, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating variables\n",
    "# list for the merged pixel data\n",
    "dataset_list = []\n",
    "# list of the label data\n",
    "label_list = []\n",
    "\n",
    "\n",
    "\n",
    "# go through all categories\n",
    "# \n",
    "for category in category_list:\n",
    "    \n",
    "    category_dir = os.path.join(patch_dir, category)\n",
    "    print  'the path into the categories is: ', category_dir\n",
    "    \n",
    "    sub_categories_dir_list = (os.listdir(category_dir))\n",
    "    print 'the sub categories are : ', sub_categories_dir_list\n",
    "    sub_categories_dir_list.pop(0)\n",
    "        \n",
    "    for subCategory in sub_categories_dir_list:\n",
    "            \n",
    "        subCategory_dir = os.path.join(category_dir, subCategory)\n",
    "        print  'the path into the sub categories is: '\n",
    "        print subCategory_dir\n",
    "        \n",
    "        image_files = (os.listdir(subCategory_dir))\n",
    "            \n",
    "        for file in image_files:\n",
    "                \n",
    "            if file.find('.bmp') > 0:\n",
    "                \n",
    "                # load the .bmp file into array       \n",
    "                image = misc.imread(os.path.join(subCategory_dir,file), flatten= 0)\n",
    "                # append the array to the dataset list\n",
    "                dataset_list.append(image)\n",
    "                \n",
    "                # created rotated copies of images\n",
    "                image90 = np.rot90(image)\n",
    "                dataset_list.append(image90)\n",
    "                \n",
    "                image180 = np.rot90(image90)\n",
    "                dataset_list.append(image180)\n",
    "                \n",
    "                image270 = np.rot90(image180)\n",
    "                dataset_list.append(image270)\n",
    "                \n",
    "                if category == 'consolidation':    \n",
    "                    label_list.append(0)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(0)\n",
    "                    label_list.append(0)\n",
    "                    label_list.append(0)\n",
    "                    \n",
    "                if category == 'fibrosis':    \n",
    "                    label_list.append(1)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(1)\n",
    "                    label_list.append(1)\n",
    "                    label_list.append(1)\n",
    "                    \n",
    "                if category == 'ground_glass':    \n",
    "                    label_list.append(2)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(2)\n",
    "                    label_list.append(2)\n",
    "                    label_list.append(2)\n",
    "                    \n",
    "                if category == 'healthy':    \n",
    "                    label_list.append(3)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(3)\n",
    "                    label_list.append(3)\n",
    "                    label_list.append(3)\n",
    "                    \n",
    "                if category == 'micronodules':    \n",
    "                    label_list.append(4)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(4)\n",
    "                    label_list.append(4)\n",
    "                    label_list.append(4)\n",
    "                    \n",
    "                if category == 'reticulation':    \n",
    "                    label_list.append(5)\n",
    "                    # append also lables for rotated images\n",
    "                    label_list.append(5)\n",
    "                    label_list.append(5)\n",
    "                    label_list.append(5)\n",
    "                                 \n",
    "# transform dataset list into numpy array                   \n",
    "dataset = np.array(dataset_list)\n",
    "\n",
    "# use only one of the 3 color channels as greyscale info\n",
    "X = dataset[:,:, :,1]\n",
    "\n",
    "print 'dataset shape is now: ', X.shape\n",
    "\n",
    "# \n",
    "y = np.array(label_list)\n",
    "# sampling item 22\n",
    "y[22]\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20948, 32, 32)\n",
      "(20948,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use only x thousand items out of the total\n",
    "d1 = X.shape[0]\n",
    "d2 = d1 % 1000\n",
    "\n",
    "d3 = d1 - d2\n",
    "d3\n",
    "X = X[0:d3]\n",
    "y = y[0:d3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 32)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32)\n",
      "(5000, 32, 32)\n",
      "(5000, 32, 32)\n",
      "(10000,)\n",
      "(5000,)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_intermediate, y_train, y_intermediate = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_intermediate, y_intermediate, test_size=0.5, random_state=42)\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape\n",
    "print y_val.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the dataset and label set into serial formatted pkl \n",
    "\n",
    "pickle.dump(X_train, open( \"../pickle/X_train.pkl\", \"wb\" ))\n",
    "pickle.dump(X_test, open( \"../pickle/X_test.pkl\", \"wb\" ))\n",
    "pickle.dump(X_val, open( \"../pickle/X_val.pkl\", \"wb\" ))\n",
    "pickle.dump(y_train, open( \"../pickle/y_train.pkl\", \"wb\" ))\n",
    "pickle.dump(y_test, open( \"../pickle/y_test.pkl\", \"wb\" ))\n",
    "pickle.dump(y_val, open( \"../pickle/y_val.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing if pickls was working fine\n",
    "recuperated_X_train = pickle.load( open( \"../pickle/X_train.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuperated_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
