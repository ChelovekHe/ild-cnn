{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how to store models and weights\n",
    "\n",
    "    this notebook is using CIFAR10 dataset \n",
    "    Keras version 1.0.2\n",
    "    Theano version 0.9.0dev1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# definition of variable\n",
    "# data augmentation is set to false as it creates an error on my machine\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 1       # only one epoch as I don't any accuracy, I only need a trained model \n",
    "data_augmentation = False\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# loading thje data\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definition of the model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                        input_shape=(img_channels, img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some processing: change to float type and divide by 255\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 634s - loss: 1.4225 - acc: 0.4843 - val_loss: 1.2105 - val_acc: 0.5636\n"
     ]
    }
   ],
   "source": [
    "# again, no data augmentation used\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## center part: saving model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the model is aved in the JSON string, eventually , this string needs to be saved in a file\n",
    "\n",
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Convolution2D\", \"config\": {\"b_regularizer\": null, \"W_constraint\": null, \"b_constraint\": null, \"name\": \"convolution2d_1\", \"activity_regularizer\": null, \"trainable\": true, \"dim_ordering\": \"th\", \"nb_col\": 3, \"subsample\": [1, 1], \"init\": \"glorot_uniform\", \"bias\": true, \"nb_filter\": 32, \"input_dtype\": \"float32\", \"border_mode\": \"same\", \"batch_input_shape\": [null, 3, 32, 32], \"W_regularizer\": null, \"activation\": \"linear\", \"nb_row\": 3}}, {\"class_name\": \"Activation\", \"config\": {\"activation\": \"relu\", \"trainable\": true, \"name\": \"activation_1\"}}, {\"class_name\": \"Convolution2D\", \"config\": {\"W_constraint\": null, \"b_constraint\": null, \"name\": \"convolution2d_2\", \"activity_regularizer\": null, \"trainable\": true, \"dim_ordering\": \"th\", \"nb_col\": 3, \"subsample\": [1, 1], \"init\": \"glorot_uniform\", \"bias\": true, \"nb_filter\": 32, \"border_mode\": \"valid\", \"b_regularizer\": null, \"W_regularizer\": null, \"activation\": \"linear\", \"nb_row\": 3}}, {\"class_name\": \"Activation\", \"config\": {\"activation\": \"relu\", \"trainable\": true, \"name\": \"activation_2\"}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"maxpooling2d_1\", \"trainable\": true, \"dim_ordering\": \"th\", \"pool_size\": [2, 2], \"strides\": [2, 2], \"border_mode\": \"valid\"}}, {\"class_name\": \"Dropout\", \"config\": {\"p\": 0.25, \"trainable\": true, \"name\": \"dropout_1\"}}, {\"class_name\": \"Convolution2D\", \"config\": {\"W_constraint\": null, \"b_constraint\": null, \"name\": \"convolution2d_3\", \"activity_regularizer\": null, \"trainable\": true, \"dim_ordering\": \"th\", \"nb_col\": 3, \"subsample\": [1, 1], \"init\": \"glorot_uniform\", \"bias\": true, \"nb_filter\": 64, \"border_mode\": \"same\", \"b_regularizer\": null, \"W_regularizer\": null, \"activation\": \"linear\", \"nb_row\": 3}}, {\"class_name\": \"Activation\", \"config\": {\"activation\": \"relu\", \"trainable\": true, \"name\": \"activation_3\"}}, {\"class_name\": \"Convolution2D\", \"config\": {\"W_constraint\": null, \"b_constraint\": null, \"name\": \"convolution2d_4\", \"activity_regularizer\": null, \"trainable\": true, \"dim_ordering\": \"th\", \"nb_col\": 3, \"subsample\": [1, 1], \"init\": \"glorot_uniform\", \"bias\": true, \"nb_filter\": 64, \"border_mode\": \"valid\", \"b_regularizer\": null, \"W_regularizer\": null, \"activation\": \"linear\", \"nb_row\": 3}}, {\"class_name\": \"Activation\", \"config\": {\"activation\": \"relu\", \"trainable\": true, \"name\": \"activation_4\"}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"maxpooling2d_2\", \"trainable\": true, \"dim_ordering\": \"th\", \"pool_size\": [2, 2], \"strides\": [2, 2], \"border_mode\": \"valid\"}}, {\"class_name\": \"Dropout\", \"config\": {\"p\": 0.25, \"trainable\": true, \"name\": \"dropout_2\"}}, {\"class_name\": \"Flatten\", \"config\": {\"trainable\": true, \"name\": \"flatten_1\"}}, {\"class_name\": \"Dense\", \"config\": {\"W_constraint\": null, \"b_constraint\": null, \"name\": \"dense_1\", \"activity_regularizer\": null, \"trainable\": true, \"init\": \"glorot_uniform\", \"bias\": true, \"input_dim\": null, \"b_regularizer\": null, \"W_regularizer\": null, \"activation\": \"linear\", \"output_dim\": 512}}, {\"class_name\": \"Activation\", \"config\": {\"activation\": \"relu\", \"trainable\": true, \"name\": \"activation_5\"}}, {\"class_name\": \"Dropout\", \"config\": {\"p\": 0.5, \"trainable\": true, \"name\": \"dropout_3\"}}, {\"class_name\": \"Dense\", \"config\": {\"W_constraint\": null, \"b_constraint\": null, \"name\": \"dense_2\", \"activity_regularizer\": null, \"trainable\": true, \"init\": \"glorot_uniform\", \"bias\": true, \"input_dim\": null, \"b_regularizer\": null, \"W_regularizer\": null, \"activation\": \"linear\", \"output_dim\": 10}}, {\"class_name\": \"Activation\", \"config\": {\"activation\": \"softmax\", \"trainable\": true, \"name\": \"activation_6\"}}]}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the weights in model_weights file (binary)\n",
    "\n",
    "model.save_weights('./model_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate a dataset without labels for which we need a predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a set of 10 data records (copied from the training set)\n",
    "\n",
    "X_test = X_train[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = y_train[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4],\n",
       "       [7],\n",
       "       [7],\n",
       "       [2],\n",
       "       [9],\n",
       "       [9],\n",
       "       [9],\n",
       "       [3],\n",
       "       [2],\n",
       "       [6]], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n",
      "10/10 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "# predict method of model\n",
    "\n",
    "classes = model.predict_classes(X_test, batch_size=10)\n",
    "proba = model.predict_proba(X_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 4, 0, 9, 8, 9, 3, 6, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result as categories\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.25784989e-05,   3.54626764e-06,   5.67369871e-02,\n",
       "          1.48985386e-02,   7.32406616e-01,   3.44633800e-03,\n",
       "          1.90707698e-01,   1.68967794e-03,   9.36454398e-06,\n",
       "          8.68152711e-06],\n",
       "       [  1.22841168e-02,   6.62187487e-03,   3.16324346e-02,\n",
       "          2.28643995e-02,   1.89307630e-01,   3.49498689e-02,\n",
       "          6.40458008e-03,   6.81697726e-01,   1.54588430e-03,\n",
       "          1.26915043e-02],\n",
       "       [  2.50246257e-01,   7.98121002e-03,   1.10884674e-01,\n",
       "          2.75632809e-03,   3.18268746e-01,   5.70206856e-03,\n",
       "          1.80390792e-03,   2.86502570e-01,   2.10575131e-03,\n",
       "          1.37484809e-02],\n",
       "       [  2.78373241e-01,   2.64492244e-01,   1.23803265e-01,\n",
       "          3.83267775e-02,   5.63055873e-02,   1.53252091e-02,\n",
       "          1.16270510e-02,   3.28190550e-02,   1.23840779e-01,\n",
       "          5.50868064e-02],\n",
       "       [  4.21216451e-02,   1.01479463e-01,   2.81665903e-02,\n",
       "          3.88136059e-02,   2.77727880e-02,   1.97520517e-02,\n",
       "          3.34110819e-02,   5.26774749e-02,   7.63741881e-02,\n",
       "          5.79431117e-01],\n",
       "       [  8.05081949e-02,   2.38069445e-02,   3.67215648e-02,\n",
       "          1.64215434e-02,   1.66723896e-02,   5.88954194e-03,\n",
       "          4.47117537e-03,   1.46384528e-02,   6.96166337e-01,\n",
       "          1.04703844e-01],\n",
       "       [  1.49730474e-01,   9.70455259e-02,   1.75643340e-02,\n",
       "          6.72371639e-03,   9.26561002e-03,   3.43240611e-03,\n",
       "          9.01061483e-03,   1.52359838e-02,   1.31443501e-01,\n",
       "          5.60547829e-01],\n",
       "       [  1.09809125e-02,   9.92346089e-03,   1.15670368e-01,\n",
       "          3.02088618e-01,   1.65185720e-01,   7.17201829e-02,\n",
       "          2.50538260e-01,   3.47199515e-02,   2.68109683e-02,\n",
       "          1.23615768e-02],\n",
       "       [  1.53647957e-03,   3.11704818e-04,   2.74209809e-02,\n",
       "          1.90136999e-01,   1.64030306e-02,   1.84975006e-02,\n",
       "          7.35258400e-01,   5.73586347e-03,   2.38088216e-03,\n",
       "          2.31816480e-03],\n",
       "       [  9.32171009e-03,   1.89451575e-02,   3.34662274e-02,\n",
       "          4.47628163e-02,   2.49381978e-02,   9.30419099e-03,\n",
       "          7.32282043e-01,   4.07368038e-03,   2.72570048e-02,\n",
       "          9.56489965e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result as probabilties, the highest probability for each item is chosen for the classification\n",
    "\n",
    "proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading model and weights back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load back model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "model_reloaded = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load back weights\n",
    "\n",
    "model_reloaded.load_weights('./model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile model as before\n",
    "\n",
    "model_reloaded.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n",
      "10/10 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "# predict and check classification and probabilities are the same\n",
    "\n",
    "classes = model_reloaded.predict_classes(X_test, batch_size=10)\n",
    "proba = model_reloaded.predict_proba(X_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 4, 0, 9, 8, 9, 3, 6, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.25784989e-05,   3.54626764e-06,   5.67369871e-02,\n",
       "          1.48985386e-02,   7.32406616e-01,   3.44633800e-03,\n",
       "          1.90707698e-01,   1.68967794e-03,   9.36454398e-06,\n",
       "          8.68152711e-06],\n",
       "       [  1.22841168e-02,   6.62187487e-03,   3.16324346e-02,\n",
       "          2.28643995e-02,   1.89307630e-01,   3.49498689e-02,\n",
       "          6.40458008e-03,   6.81697726e-01,   1.54588430e-03,\n",
       "          1.26915043e-02],\n",
       "       [  2.50246257e-01,   7.98121002e-03,   1.10884674e-01,\n",
       "          2.75632809e-03,   3.18268746e-01,   5.70206856e-03,\n",
       "          1.80390792e-03,   2.86502570e-01,   2.10575131e-03,\n",
       "          1.37484809e-02],\n",
       "       [  2.78373241e-01,   2.64492244e-01,   1.23803265e-01,\n",
       "          3.83267775e-02,   5.63055873e-02,   1.53252091e-02,\n",
       "          1.16270510e-02,   3.28190550e-02,   1.23840779e-01,\n",
       "          5.50868064e-02],\n",
       "       [  4.21216451e-02,   1.01479463e-01,   2.81665903e-02,\n",
       "          3.88136059e-02,   2.77727880e-02,   1.97520517e-02,\n",
       "          3.34110819e-02,   5.26774749e-02,   7.63741881e-02,\n",
       "          5.79431117e-01],\n",
       "       [  8.05081949e-02,   2.38069445e-02,   3.67215648e-02,\n",
       "          1.64215434e-02,   1.66723896e-02,   5.88954194e-03,\n",
       "          4.47117537e-03,   1.46384528e-02,   6.96166337e-01,\n",
       "          1.04703844e-01],\n",
       "       [  1.49730474e-01,   9.70455259e-02,   1.75643340e-02,\n",
       "          6.72371639e-03,   9.26561002e-03,   3.43240611e-03,\n",
       "          9.01061483e-03,   1.52359838e-02,   1.31443501e-01,\n",
       "          5.60547829e-01],\n",
       "       [  1.09809125e-02,   9.92346089e-03,   1.15670368e-01,\n",
       "          3.02088618e-01,   1.65185720e-01,   7.17201829e-02,\n",
       "          2.50538260e-01,   3.47199515e-02,   2.68109683e-02,\n",
       "          1.23615768e-02],\n",
       "       [  1.53647957e-03,   3.11704818e-04,   2.74209809e-02,\n",
       "          1.90136999e-01,   1.64030306e-02,   1.84975006e-02,\n",
       "          7.35258400e-01,   5.73586347e-03,   2.38088216e-03,\n",
       "          2.31816480e-03],\n",
       "       [  9.32171009e-03,   1.89451575e-02,   3.34662274e-02,\n",
       "          4.47628163e-02,   2.49381978e-02,   9.30419099e-03,\n",
       "          7.32282043e-01,   4.07368038e-03,   2.72570048e-02,\n",
       "          9.56489965e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
