{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how to store models and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for a single-input model with 2 classes (binary):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=784, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24882621  0.710184    0.92410453  0.85145122  0.22397905  0.91876413\n",
      "   0.5877475   0.76065931  0.94751018  0.94973886  0.32395456  0.26689061\n",
      "   0.04350216  0.2565618   0.54768976  0.42013758  0.02570492  0.6400703\n",
      "   0.31580274  0.88136882  0.16862324  0.0206817   0.8260987   0.33050945\n",
      "   0.90435162  0.24539079  0.25840013  0.85956474  0.3827791   0.73972524\n",
      "   0.8829049   0.7346809   0.5720487   0.23428296  0.95161323  0.71684246\n",
      "   0.38202186  0.40694683  0.56897849  0.64413493  0.65371048  0.44529853\n",
      "   0.37619888  0.67098132  0.88963412  0.45299328  0.87940893  0.70937069\n",
      "   0.26846029  0.4621655   0.64742214  0.00201017  0.93971136  0.61418142\n",
      "   0.7932996   0.13831434  0.0955615   0.60002949  0.71863672  0.41290304\n",
      "   0.05025649  0.63927785  0.47161616  0.4612667   0.76951679  0.46684059\n",
      "   0.14819439  0.82477572  0.73366526  0.45073917  0.85700637  0.12726438\n",
      "   0.54956624  0.11234827  0.26005093  0.42850911  0.19528012  0.43905527\n",
      "   0.45188583  0.91842417  0.92033215  0.71183222  0.37245755  0.53079195\n",
      "   0.55122425  0.72730643  0.09977119  0.39506774  0.3046596   0.09466226\n",
      "   0.11900662  0.44894888  0.12405787  0.27833956  0.05924056  0.005169\n",
      "   0.62127492  0.56657952  0.41304715  0.77300247  0.9164989   0.55634508\n",
      "   0.36255436  0.64684573  0.43381027  0.09061743  0.30977663  0.51895771\n",
      "   0.76609558  0.35078545  0.60626451  0.30890391  0.16607665  0.93892748\n",
      "   0.44827172  0.65860603  0.08989172  0.56708208  0.77272582  0.04347269\n",
      "   0.59388648  0.6269264   0.64619108  0.37128587  0.83531603  0.19950344\n",
      "   0.01955509  0.44515775  0.03367547  0.78918441  0.86213903  0.54737858\n",
      "   0.66204119  0.95767607  0.69646039  0.64327542  0.77140639  0.25800981\n",
      "   0.61754954  0.69049201  0.40442065  0.97707758  0.19811436  0.83701012\n",
      "   0.93378268  0.99767901  0.32319369  0.96790089  0.28472255  0.00158905\n",
      "   0.14202363  0.28089927  0.72754225  0.7176279   0.32582661  0.98688267\n",
      "   0.74292375  0.4493413   0.19735392  0.89823599  0.12870843  0.35614018\n",
      "   0.08579174  0.17038803  0.62678282  0.59392985  0.10260451  0.89795825\n",
      "   0.14123485  0.86051445  0.29473189  0.60570468  0.37475935  0.91204308\n",
      "   0.98595215  0.96463997  0.40807547  0.34093216  0.13872385  0.72218029\n",
      "   0.57602256  0.13496374  0.98276618  0.6336585   0.28777487  0.80911958\n",
      "   0.78633782  0.120579    0.62962526  0.20808247  0.54074918  0.25425921\n",
      "   0.95854689  0.51269092  0.9194404   0.16994759  0.18207233  0.40016239\n",
      "   0.17873404  0.59751031  0.97477731  0.7022901   0.43927723  0.10943176\n",
      "   0.56586011  0.04510811  0.50962181  0.7139033   0.67248144  0.3270795\n",
      "   0.97500912  0.42034872  0.2201039   0.52992251  0.15457782  0.32262193\n",
      "   0.20881263  0.14706488  0.75260108  0.33667138  0.80577806  0.66032508\n",
      "   0.33332749  0.49069639  0.4066239   0.96761082  0.46552622  0.09086893\n",
      "   0.49914012  0.85374108  0.47518627  0.57076478  0.5273777   0.75278067\n",
      "   0.55085081  0.16322146  0.77957606  0.83697028  0.59727424  0.32338736\n",
      "   0.47105763  0.81585451  0.41969507  0.06231964  0.81426566  0.91043473\n",
      "   0.86627282  0.06130063  0.22303911  0.66570403  0.28857436  0.77231296\n",
      "   0.73325036  0.4824683   0.53547741  0.90746206  0.98239022  0.05270239\n",
      "   0.04416021  0.1474669   0.818551    0.41062674  0.22816071  0.42505281\n",
      "   0.43147763  0.07141485  0.96233319  0.07829543  0.94923237  0.87126563\n",
      "   0.31812696  0.93020984  0.29651304  0.59461216  0.78794552  0.46234502\n",
      "   0.35564911  0.97300646  0.37229646  0.14970865  0.08772054  0.38440407\n",
      "   0.91024629  0.12324917  0.46125304  0.32693935  0.21559489  0.2930634\n",
      "   0.56021425  0.8281806   0.39911449  0.22831313  0.1969773   0.26899803\n",
      "   0.48190098  0.87831731  0.82144983  0.75406695  0.17966582  0.81389437\n",
      "   0.83453446  0.37071858  0.19288406  0.92844452  0.84624101  0.25866953\n",
      "   0.09186311  0.09702745  0.94711163  0.49944051  0.62129113  0.60763628\n",
      "   0.96178911  0.97171549  0.4400167   0.85303284  0.05670844  0.03093329\n",
      "   0.40427873  0.17172371  0.3796596   0.54854939  0.95785477  0.69624721\n",
      "   0.57300616  0.52906626  0.34647975  0.28564811  0.23580391  0.59262502\n",
      "   0.86150618  0.65471063  0.86477421  0.07245609  0.33843016  0.04331995\n",
      "   0.25053491  0.4577899   0.74110187  0.72202533  0.96167765  0.11988751\n",
      "   0.25238567  0.26759307  0.46587405  0.83840852  0.84880097  0.08388497\n",
      "   0.45224877  0.52844277  0.38579186  0.40206809  0.08952442  0.46693217\n",
      "   0.05169475  0.99487533  0.43309327  0.78930938  0.91031762  0.37271078\n",
      "   0.05979788  0.12501864  0.55498511  0.55487931  0.87613687  0.65464305\n",
      "   0.95580375  0.25820469  0.39620437  0.09378958  0.32171795  0.50845293\n",
      "   0.58374531  0.40279354  0.23464935  0.49232228  0.19725365  0.01843477\n",
      "   0.2404969   0.75478406  0.88279038  0.9681835   0.23135232  0.74086259\n",
      "   0.00503029  0.4656431   0.06442707  0.44847529  0.88457795  0.91788882\n",
      "   0.40329961  0.74120506  0.90454896  0.52793661  0.79615009  0.77320205\n",
      "   0.74027712  0.55803094  0.94150007  0.22750729  0.26010946  0.31321551\n",
      "   0.66559871  0.57333063  0.84922301  0.36022974  0.07019744  0.18931082\n",
      "   0.5046337   0.65078188  0.69292536  0.7303748   0.02983459  0.65538803\n",
      "   0.13873862  0.60515055  0.59731004  0.00913107  0.71428007  0.85870755\n",
      "   0.56526862  0.54575898  0.46522731  0.47814543  0.49124454  0.69713947\n",
      "   0.91604049  0.06681494  0.60330393  0.32164659  0.06971215  0.80842625\n",
      "   0.30848441  0.36865785  0.65066401  0.5332423   0.26272074  0.15007412\n",
      "   0.42485436  0.12334216  0.41242845  0.97332207  0.90289218  0.90396731\n",
      "   0.96844092  0.99879426  0.74130972  0.91573138  0.66364154  0.34552229\n",
      "   0.32003154  0.36649731  0.41040756  0.62646791  0.33737748  0.90038874\n",
      "   0.28568113  0.96549281  0.84447108  0.06031719  0.38475489  0.94391116\n",
      "   0.42689406  0.17153234  0.4917526   0.55484155  0.18010146  0.23684501\n",
      "   0.41809439  0.41656374  0.02281575  0.52804287  0.58105627  0.0505925\n",
      "   0.43018466  0.97219674  0.00602902  0.53079168  0.52967875  0.82413501\n",
      "   0.88741288  0.9398951   0.57783789  0.91078377  0.55306372  0.61898882\n",
      "   0.32004462  0.66447719  0.36242585  0.82249791  0.04191048  0.38404521\n",
      "   0.50734684  0.06868154  0.3557116   0.09963321  0.29302519  0.01912218\n",
      "   0.61644897  0.42150427  0.38983591  0.77753476  0.52572944  0.39215448\n",
      "   0.96999357  0.86618231  0.28032924  0.96211013  0.18722512  0.85795614\n",
      "   0.92896447  0.51260526  0.54366089  0.32324192  0.81677564  0.69844872\n",
      "   0.01833025  0.45944247  0.23623767  0.89102645  0.24784717  0.1617883\n",
      "   0.88495414  0.99975813  0.41742106  0.56453701  0.85135826  0.7094616\n",
      "   0.510617    0.33808903  0.74309167  0.19621297  0.10471624  0.33848678\n",
      "   0.43087985  0.78729875  0.84721473  0.71719976  0.01661219  0.72418762\n",
      "   0.59354597  0.18717612  0.85345423  0.22640639  0.70470497  0.62774011\n",
      "   0.28055225  0.48401787  0.00386515  0.35780696  0.75558035  0.53250242\n",
      "   0.16003617  0.23595854  0.93973124  0.0450971   0.67808246  0.59685841\n",
      "   0.95366921  0.21007462  0.74026994  0.38903068  0.72922504  0.11488299\n",
      "   0.28389385  0.6051641   0.25708778  0.88854708  0.75547623  0.35686077\n",
      "   0.11107349  0.61442928  0.47019627  0.01644381  0.72070697  0.37262447\n",
      "   0.61734629  0.44761302  0.69690828  0.39116516  0.53089798  0.36421796\n",
      "   0.48400335  0.51522235  0.2987004   0.92077775  0.47349038  0.64916457\n",
      "   0.71117278  0.14481916  0.13993487  0.7436246   0.67084175  0.35277958\n",
      "   0.76787523  0.2543359   0.67370775  0.33306389  0.4631879   0.20268628\n",
      "   0.80361331  0.62971622  0.01571573  0.10210807  0.2412702   0.79714507\n",
      "   0.14189938  0.0727347   0.38421098  0.09582083  0.47983608  0.91094275\n",
      "   0.52687873  0.46518839  0.08831243  0.19602263  0.46510564  0.94421456\n",
      "   0.02152887  0.27120479  0.87819349  0.79980115  0.63867831  0.54420903\n",
      "   0.63275857  0.11475888  0.69794328  0.14216913  0.74561009  0.76687021\n",
      "   0.72146903  0.30352091  0.43839822  0.15071249  0.37158296  0.04531026\n",
      "   0.05619486  0.18015554  0.68561243  0.91436278  0.43845499  0.24536602\n",
      "   0.02465568  0.91498425  0.91861407  0.74902738  0.97681096  0.70997727\n",
      "   0.67732062  0.19818575  0.07601005  0.46700078  0.78209359  0.98187893\n",
      "   0.95219364  0.85232591  0.01293365  0.9381331   0.08690296  0.63217045\n",
      "   0.86364476  0.59174835  0.01823249  0.94277113  0.90510543  0.04616865\n",
      "   0.8953657   0.9123044   0.90894891  0.64684716  0.27819489  0.82969087\n",
      "   0.45931264  0.09756915  0.00728785  0.65660538  0.239739    0.68646634\n",
      "   0.98695049  0.67217248  0.50401374  0.35968645  0.69792093  0.96855503\n",
      "   0.37723569  0.35287658  0.57563981  0.217686    0.74279828  0.76967325\n",
      "   0.52874881  0.5918711   0.88985385  0.74549376  0.25507482  0.17932333\n",
      "   0.74731045  0.84317043  0.41162604  0.48097231  0.84875027  0.36798416\n",
      "   0.7966552   0.24628375  0.5740259   0.41554985  0.4476132   0.53898206\n",
      "   0.42029027  0.02592295  0.58608234  0.96452438  0.50494329  0.5084689\n",
      "   0.77864073  0.63405257  0.00638328  0.78902894  0.15972011  0.65868537\n",
      "   0.86825035  0.90146662  0.8172791   0.38107357  0.62246982  0.40639065\n",
      "   0.02742157  0.33622379  0.21311337  0.76841368  0.94942544  0.87486405\n",
      "   0.99071136  0.51479103  0.38576021  0.44154493  0.95139935  0.67190807\n",
      "   0.73631786  0.50768284  0.22859406  0.65989287  0.43858918  0.94136523\n",
      "   0.53995112  0.21418988  0.18977811  0.93551397  0.88242687  0.99447475\n",
      "   0.32984399  0.3995436   0.43400868  0.50492171  0.43623561  0.08950613\n",
      "   0.37405806  0.34258112  0.21923741  0.23991462  0.48322142  0.38215337\n",
      "   0.49603302  0.36894454  0.7855725   0.55143569  0.99712923  0.30058298\n",
      "   0.56505765  0.75065745  0.00269427  0.78267483  0.83389832  0.58373036\n",
      "   0.45202052  0.07280856  0.90565217  0.24607169  0.67104137  0.78107916\n",
      "   0.96536492  0.86809663  0.76519223  0.58035745]]\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 784))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "print data[0:1]\n",
    "print labels[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 7.6523 - acc: 0.5200     \n"
     ]
    }
   ],
   "source": [
    "# train the model, iterating on the data in batches\n",
    "# of 32 samples\n",
    "prediction = model.fit(data, labels, nb_epoch=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.random.random((10, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s\n",
      "10/10 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "classes = model.predict_classes(X_test, batch_size=32)\n",
    "proba = model.predict_proba(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
